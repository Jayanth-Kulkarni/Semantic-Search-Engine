{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import glob\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import re\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from nltk import sent_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk import map_tag\n",
    "from sklearn.metrics import classification_report\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10085 entries, 0 to 10084\n",
      "Data columns (total 11 columns):\n",
      "id                  10085 non-null object\n",
      "title               10085 non-null object\n",
      "title_small         10085 non-null object\n",
      "year                10085 non-null int64\n",
      "date                9673 non-null object\n",
      "unnamed             6636 non-null object\n",
      "conference          10085 non-null object\n",
      "conference_short    10085 non-null object\n",
      "reference1          15 non-null object\n",
      "reference2          10085 non-null object\n",
      "reference3          10085 non-null int64\n",
      "dtypes: int64(2), object(9)\n",
      "memory usage: 866.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# just to see the non null objects.\n",
    "icse = pd.read_csv(\"icse_id.txt\", delimiter='\\t')\n",
    "icse.columns = ['id','title','title_small','year','date','unnamed','conference','conference_short','reference1','reference2','reference3']\n",
    "icse.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4195 entries, 0 to 4194\n",
      "Data columns (total 11 columns):\n",
      "id                  4195 non-null object\n",
      "title               4195 non-null object\n",
      "title_small         4195 non-null object\n",
      "year                4195 non-null int64\n",
      "date                3811 non-null object\n",
      "unnamed             2408 non-null object\n",
      "conference          4195 non-null object\n",
      "conference_short    4195 non-null object\n",
      "reference1          1420 non-null object\n",
      "reference2          4195 non-null object\n",
      "reference3          4195 non-null int64\n",
      "dtypes: int64(2), object(9)\n",
      "memory usage: 360.6+ KB\n"
     ]
    }
   ],
   "source": [
    "sigmod = pd.read_csv(\"sigmod_id.txt\", delimiter='\\t')\n",
    "sigmod.columns = ['id','title','title_small','year','date','unnamed','conference','conference_short','reference1','reference2','reference3']\n",
    "sigmod.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4323 entries, 0 to 4322\n",
      "Data columns (total 11 columns):\n",
      "id                  4323 non-null object\n",
      "title               4323 non-null object\n",
      "title_small         4323 non-null object\n",
      "year                4323 non-null int64\n",
      "date                3969 non-null object\n",
      "unnamed             1224 non-null object\n",
      "conference          4323 non-null object\n",
      "conference_short    4323 non-null object\n",
      "reference1          4007 non-null object\n",
      "reference2          4323 non-null object\n",
      "reference3          4323 non-null int64\n",
      "dtypes: int64(2), object(9)\n",
      "memory usage: 371.6+ KB\n"
     ]
    }
   ],
   "source": [
    "vldb = pd.read_csv(\"vldb_id.txt\", delimiter='\\t')\n",
    "vldb.columns = ['id','title','title_small','year','date','unnamed','conference','conference_short','reference1','reference2','reference3']\n",
    "vldb.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "allFiles = glob.glob(\"./*.txt\")\n",
    "frame = pd.DataFrame()\n",
    "list_ = []\n",
    "for file_ in allFiles:\n",
    "    df = pd.read_csv(file_,delimiter='\\t')\n",
    "    df.columns = ['id','title','title_small','year','date','unnamed','conference','conference_short','reference1','reference2','reference3']\n",
    "    list_.append(df)\n",
    "frame = pd.concat(list_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             id                                              title  \\\n",
      "0      7E3FCD58  Structural trend analysis for online social ne...   \n",
      "1      07803372  SQL/AA: Executing SQL on an Asymmetric Archite...   \n",
      "2      7993CFAF  SCOUT: prefetching for latent structure follow...   \n",
      "3      61F6E244  Probabilistic nearest neighbor queries on unce...   \n",
      "4      7DE9428F  SEDA: a system for search, exploration, discov...   \n",
      "5      7EB4C1D8  HadoopDB: an architectural hybrid of MapReduce...   \n",
      "6      772EA93B  Efficient implementation of generalized quanti...   \n",
      "7      7AEF45E2        Advanced processing for ontological queries   \n",
      "8      7EC996E4      Rose : compressed, log-structured replication   \n",
      "9      79B67DB3  Updatable and Evolvable Transforms for Virtual...   \n",
      "10     6C6A912F  Calibrating data to sensitivity in private dat...   \n",
      "11     7F201A23  Effectively indexing uncertain moving objects ...   \n",
      "12     7EE41A1A  WOO: a scalable and multi-tenant platform for ...   \n",
      "13     802FA533  Predictable performance for unpredictable work...   \n",
      "14     78484CC4  Lahar demonstration: Warehousing markovian str...   \n",
      "15     805F6B87  Managing and querying transaction-time databas...   \n",
      "16     8073C414  H-store: a high-performance, distributed main ...   \n",
      "17     844EEA06  Large-scale distributed graph computing system...   \n",
      "18     7C1DBB7D    Myriad: scalable and expressive data generation   \n",
      "19     816D88F0  Prefix based numbering schemes for XML: techni...   \n",
      "20     7D63DE2A            Constrained locally weighted clustering   \n",
      "21     7511B404  Dwarfs in the rearview mirror: how big are the...   \n",
      "22     799D18BA  Learning and intelligent optimization (LION): ...   \n",
      "23     834D5557  E-store: fine-grained elastic partitioning for...   \n",
      "24     7AF7131C  An adaptive updating protocol for reducing mov...   \n",
      "25     817106D0  Clustera: an integrated computation and data m...   \n",
      "26     7E596971  Hum-a-song: a subsequence matching with gaps-r...   \n",
      "27     80171D9E  Locking key ranges with unbundled transaction ...   \n",
      "28     7EB32BB1  Streaming similarity search over one billion t...   \n",
      "29     7BD9183F                      Time for our field to grow up   \n",
      "...         ...                                                ...   \n",
      "10055  7570ABF6               Abstract syntax from concrete syntax   \n",
      "10056  0AE08FC8  A Discrete Event Simulation for Utility Accrua...   \n",
      "10057  80791F44  Relationship function, relationship quality, a...   \n",
      "10058  7C3EA18A                    Effort estimation using analogy   \n",
      "10059  6EBC4F82  Issues and solutions for running a full year s...   \n",
      "10060  7B780577  4th international workshop on software enginee...   \n",
      "10061  7D5C6CAD  Requirements for a layered software architectu...   \n",
      "10062  7FEDD9D1  Experiences with an environment generation system   \n",
      "10063  310AC84F  The 22th International Conference on Software ...   \n",
      "10064  81EFB510  Extension and application based on robot testi...   \n",
      "10065  006D2CF0  A Verified Protocol to Implement Multi-way Syn...   \n",
      "10066  80A7520E  Cross-platform testing and maintenance of web ...   \n",
      "10067  7BCB9DD8  1st international workshop on TEchnical and LE...   \n",
      "10068  7B834724  Making software process simulation modeling ag...   \n",
      "10069  80B469D0  A new remory management mechanism based on emb...   \n",
      "10070  80C12F9E  An Enhancement of Decimation Process using Fas...   \n",
      "10071  80C8A61C  Co-adapting human collaborations and software ...   \n",
      "10072  7CDD6103  Dobby: A Methodology for the Study of Replication   \n",
      "10073  80AE4674                         Teaching black box testing   \n",
      "10074  7BB905A7  Models and processes for the evaluation of off...   \n",
      "10075  5E96BCE8  Efficient computation of dominance in componen...   \n",
      "10076  7B8318A1  Analysis on games modeling among multi-agents ...   \n",
      "10077  80E73331         Building and using pluggable type-checkers   \n",
      "10078  77CC29E4  Generalization and Theory-Building in Software...   \n",
      "10079  7D24B1AF  Automated Detection of Client-State Manipulati...   \n",
      "10080  7AE8B627  DIG: A Dynamic Invariant Generator for Polynom...   \n",
      "10081  7A8831FC  Introduction to the Special Issue Internationa...   \n",
      "10082  7FD4CA5A      On the Comprehension of Program Comprehension   \n",
      "10083  7AD1AA9A  Some Code Smells Have a Significant but Small ...   \n",
      "10084  7A1FC0CA  Amplifying Tests to Validate Exception Handlin...   \n",
      "\n",
      "                                             title_small  year        date  \\\n",
      "0      structural trend analysis for online social ne...  2011  2011/07/01   \n",
      "1      sql aa executing sql on an asymmetric architec...  2014     2014/09   \n",
      "2      scout prefetching for latent structure followi...  2012  2012/07/01   \n",
      "3      probabilistic nearest neighbor queries on unce...  2013  2013/05/15   \n",
      "4      seda a system for search exploration discovery...  2008  2008/08/01   \n",
      "5      hadoopdb an architectural hybrid of mapreduce ...  2009  2009/08/01   \n",
      "6      efficient implementation of generalized quanti...  2013  2013/02/01   \n",
      "7            advanced processing for ontological queries  2010  2010/09/01   \n",
      "8             rose compressed log structured replication  2008  2008/08/01   \n",
      "9      updatable and evolvable transforms for virtual...  2010  2010/09/01   \n",
      "10     calibrating data to sensitivity in private dat...  2014  2014/04/01   \n",
      "11     effectively indexing uncertain moving objects ...  2009        2009   \n",
      "12     woo a scalable and multi tenant platform for c...  2013  2013/08/27   \n",
      "13     predictable performance for unpredictable work...  2009  2009/08/01   \n",
      "14     lahar demonstration warehousing markovian streams  2009  2009/08/01   \n",
      "15     managing and querying transaction time databas...  2008  2008/08/01   \n",
      "16     h store a high performance distributed main me...  2008  2008/08/01   \n",
      "17     large scale distributed graph computing system...  2014  2014/11/01   \n",
      "18        myriad scalable and expressive data generation  2012  2012/08/01   \n",
      "19     prefix based numbering schemes for xml techniq...  2008  2008/08/01   \n",
      "20               constrained locally weighted clustering  2008  2008/08/01   \n",
      "21     dwarfs in the rearview mirror how big are they...  2008  2008/08/01   \n",
      "22     learning and intelligent optimization lion one...  2013  2013/08/27   \n",
      "23     e store fine grained elastic partitioning for ...  2014  2014/11/01   \n",
      "24     an adaptive updating protocol for reducing mov...  2010  2010/09/01   \n",
      "25     clustera an integrated computation and data ma...  2008  2008/08/01   \n",
      "26     hum a song a subsequence matching with gaps ra...  2012  2012/08/01   \n",
      "27     locking key ranges with unbundled transaction ...  2009  2009/08/01   \n",
      "28     streaming similarity search over one billion t...  2013  2013/09/01   \n",
      "29                         time for our field to grow up  2010  2010/09/01   \n",
      "...                                                  ...   ...         ...   \n",
      "10055               abstract syntax from concrete syntax  1997  1997/05/01   \n",
      "10056  a discrete event simulation for utility accrua...  2011  2011/06/27   \n",
      "10057  relationship function relationship quality and...  2012     2012/06   \n",
      "10058                    effort estimation using analogy  1996  1996/05/01   \n",
      "10059  issues and solutions for running a full year s...  1998        1998   \n",
      "10060  4th international workshop on software enginee...  2013  2013/05/18   \n",
      "10061  requirements for a layered software architectu...  1996  1996/05/01   \n",
      "10062  experiences with an environment generation system  1991  1991/05/01   \n",
      "10063  the 22th international conference on software ...  2000     2000/11   \n",
      "10064  extension and application based on robot testi...  2015     2015/09   \n",
      "10065  a verified protocol to implement multi way syn...  2013  2013/09/23   \n",
      "10066  cross platform testing and maintenance of web ...  2014  2014/05/31   \n",
      "10067  1st international workshop on technical and le...  2015  2015/05/16   \n",
      "10068  making software process simulation modeling ag...  2004        2004   \n",
      "10069  a new remory management mechanism based on emb...  2012     2012/06   \n",
      "10070  an enhancement of decimation process using fas...  2006     2006/11   \n",
      "10071  co adapting human collaborations and software ...  2012  2012/06/02   \n",
      "10072   dobby a methodology for the study of replication  2013  2013/09/24   \n",
      "10073                         teaching black box testing  1998        1998   \n",
      "10074  models and processes for the evaluation of off...  2005  2005/05/15   \n",
      "10075  efficient computation of dominance in componen...  2011  2011/11/14   \n",
      "10076  analysis on games modeling among multi agents ...  2011     2011/07   \n",
      "10077         building and using pluggable type checkers  2011  2011/05/21   \n",
      "10078  generalization and theory building in software...  2004        2004   \n",
      "10079  automated detection of client state manipulati...  2014  2014/09/05   \n",
      "10080  dig a dynamic invariant generator for polynomi...  2014  2014/09/05   \n",
      "10081  introduction to the special issue internationa...  2014  2014/09/05   \n",
      "10082      on the comprehension of program comprehension  2014  2014/09/05   \n",
      "10083  some code smells have a significant but small ...  2014  2014/09/05   \n",
      "10084  amplifying tests to validate exception handlin...  2014  2014/09/05   \n",
      "\n",
      "                            unnamed  \\\n",
      "0          10.14778/2021017.2021022   \n",
      "1                               NaN   \n",
      "2                               NaN   \n",
      "3                               NaN   \n",
      "4          10.14778/1454159.1454185   \n",
      "5                               NaN   \n",
      "6                               NaN   \n",
      "7                               NaN   \n",
      "8          10.14778/1453856.1453914   \n",
      "9                               NaN   \n",
      "10         10.14778/2732296.2732300   \n",
      "11         10.14778/1687627.1687762   \n",
      "12         10.14778/2536222.2536236   \n",
      "13         10.14778/1687627.1687707   \n",
      "14         10.14778/1687553.1687605   \n",
      "15                              NaN   \n",
      "16                              NaN   \n",
      "17                              NaN   \n",
      "18         10.14778/2367502.2367530   \n",
      "19         10.14778/1454159.1454228   \n",
      "20                              NaN   \n",
      "21         10.14778/1454159.1454230   \n",
      "22         10.14778/2536222.2536247   \n",
      "23         10.14778/2735508.2735514   \n",
      "24                              NaN   \n",
      "25         10.14778/1453856.1453865   \n",
      "26                              NaN   \n",
      "27         10.14778/1687627.1687658   \n",
      "28         10.14778/2556549.2556574   \n",
      "29                              NaN   \n",
      "...                             ...   \n",
      "10055      10.1109/ICSE.1997.610346   \n",
      "10056  10.1007/978-3-642-22191-0_53   \n",
      "10057   10.1109/ICSESS.2012.6269541   \n",
      "10058      10.1109/ICSE.1996.493413   \n",
      "10059      10.1109/SEEP.1998.707639   \n",
      "10060     10.1109/ICSE.2013.6606782   \n",
      "10061      10.1109/ICSE.1996.493435   \n",
      "10062      10.1109/ICSE.1991.130646   \n",
      "10063                           NaN   \n",
      "10064                           NaN   \n",
      "10065   10.1007/978-3-642-40561-7_4   \n",
      "10066                           NaN   \n",
      "10067                           NaN   \n",
      "10068           10.1049/ic:20040462   \n",
      "10069   10.1109/ICSESS.2012.6269425   \n",
      "10070                           NaN   \n",
      "10071     10.1109/ICSE.2012.6227100   \n",
      "10072                           NaN   \n",
      "10073      10.1109/SEEP.1998.707666   \n",
      "10074     10.1109/ICSE.2005.1553666   \n",
      "10075                           NaN   \n",
      "10076   10.1109/ICSESS.2011.5982280   \n",
      "10077       10.1145/1985793.1985889   \n",
      "10078           10.1049/ic:20040396   \n",
      "10079                           NaN   \n",
      "10080                           NaN   \n",
      "10081                           NaN   \n",
      "10082                           NaN   \n",
      "10083               10.1145/2629648   \n",
      "10084                           NaN   \n",
      "\n",
      "                                             conference conference_short  \\\n",
      "0                                 very large data bases             vldb   \n",
      "1                                 very large data bases             vldb   \n",
      "2                                 very large data bases             vldb   \n",
      "3                                 very large data bases             vldb   \n",
      "4                                 very large data bases             vldb   \n",
      "5                                 very large data bases             vldb   \n",
      "6                                 very large data bases             vldb   \n",
      "7                                 very large data bases             vldb   \n",
      "8                                 very large data bases             vldb   \n",
      "9                                 very large data bases             vldb   \n",
      "10                                very large data bases             vldb   \n",
      "11                                very large data bases             vldb   \n",
      "12                                very large data bases             vldb   \n",
      "13                                very large data bases             vldb   \n",
      "14                                very large data bases             vldb   \n",
      "15                                very large data bases             vldb   \n",
      "16                                very large data bases             vldb   \n",
      "17                                very large data bases             vldb   \n",
      "18                                very large data bases             vldb   \n",
      "19                                very large data bases             vldb   \n",
      "20                                very large data bases             vldb   \n",
      "21                                very large data bases             vldb   \n",
      "22                                very large data bases             vldb   \n",
      "23                                very large data bases             vldb   \n",
      "24                                very large data bases             vldb   \n",
      "25                                very large data bases             vldb   \n",
      "26                                very large data bases             vldb   \n",
      "27                                very large data bases             vldb   \n",
      "28                                very large data bases             vldb   \n",
      "29                                very large data bases             vldb   \n",
      "...                                                 ...              ...   \n",
      "10055  international conference on software engineering             icse   \n",
      "10056  international conference on software engineering             icse   \n",
      "10057  international conference on software engineering             icse   \n",
      "10058  international conference on software engineering             icse   \n",
      "10059  international conference on software engineering             icse   \n",
      "10060  international conference on software engineering             icse   \n",
      "10061  international conference on software engineering             icse   \n",
      "10062  international conference on software engineering             icse   \n",
      "10063  international conference on software engineering             icse   \n",
      "10064  international conference on software engineering             icse   \n",
      "10065  international conference on software engineering             icse   \n",
      "10066  international conference on software engineering             icse   \n",
      "10067  international conference on software engineering             icse   \n",
      "10068  international conference on software engineering             icse   \n",
      "10069  international conference on software engineering             icse   \n",
      "10070  international conference on software engineering             icse   \n",
      "10071  international conference on software engineering             icse   \n",
      "10072  international conference on software engineering             icse   \n",
      "10073  international conference on software engineering             icse   \n",
      "10074  international conference on software engineering             icse   \n",
      "10075  international conference on software engineering             icse   \n",
      "10076  international conference on software engineering             icse   \n",
      "10077  international conference on software engineering             icse   \n",
      "10078  international conference on software engineering             icse   \n",
      "10079  international conference on software engineering             icse   \n",
      "10080  international conference on software engineering             icse   \n",
      "10081  international conference on software engineering             icse   \n",
      "10082  international conference on software engineering             icse   \n",
      "10083  international conference on software engineering             icse   \n",
      "10084  international conference on software engineering             icse   \n",
      "\n",
      "      reference1 reference2  reference3  \n",
      "0       0215FD76   4390334E       18864  \n",
      "1       0215FD76   4390334E       19476  \n",
      "2       0215FD76   4390334E       19452  \n",
      "3       0215FD76   4390334E       19158  \n",
      "4       0215FD76   4390334E       19264  \n",
      "5       0215FD76   4390334E       16222  \n",
      "6       0215FD76   4390334E       19555  \n",
      "7       0215FD76   4390334E       18058  \n",
      "8       0215FD76   4390334E       18262  \n",
      "9       0215FD76   4390334E       19253  \n",
      "10      0215FD76   4390334E       19320  \n",
      "11      0215FD76   4390334E       18666  \n",
      "12      0215FD76   4390334E       19224  \n",
      "13      0215FD76   4390334E       18176  \n",
      "14      0215FD76   4390334E       19235  \n",
      "15      0215FD76   4390334E       18215  \n",
      "16      0215FD76   4390334E       17328  \n",
      "17      0215FD76   4390334E       19294  \n",
      "18      0215FD76   4390334E       18874  \n",
      "19      0215FD76   4390334E       18829  \n",
      "20      0215FD76   4390334E       18667  \n",
      "21      0215FD76   4390334E       19270  \n",
      "22      0215FD76   4390334E       19276  \n",
      "23      0215FD76   4390334E       19407  \n",
      "24      0215FD76   4390334E       18996  \n",
      "25      0215FD76   4390334E       17494  \n",
      "26      0215FD76   4390334E       19435  \n",
      "27      0215FD76   4390334E       18691  \n",
      "28      0215FD76   4390334E       19171  \n",
      "29      0215FD76   4390334E       17579  \n",
      "...          ...        ...         ...  \n",
      "10055        NaN   45FFFB88       18042  \n",
      "10056        NaN   45FFFB88       19318  \n",
      "10057        NaN   45FFFB88       19555  \n",
      "10058        NaN   45FFFB88       16407  \n",
      "10059        NaN   45FFFB88       16879  \n",
      "10060        NaN   45FFFB88       19555  \n",
      "10061        NaN   45FFFB88       18891  \n",
      "10062        NaN   45FFFB88       19421  \n",
      "10063        NaN   45FFFB88       19555  \n",
      "10064        NaN   45FFFB88       19555  \n",
      "10065        NaN   45FFFB88       19483  \n",
      "10066        NaN   45FFFB88       19555  \n",
      "10067        NaN   45FFFB88       19555  \n",
      "10068        NaN   45FFFB88       16940  \n",
      "10069        NaN   45FFFB88       19555  \n",
      "10070        NaN   45FFFB88       19555  \n",
      "10071        NaN   45FFFB88       17528  \n",
      "10072        NaN   45FFFB88       19555  \n",
      "10073        NaN   45FFFB88       17432  \n",
      "10074        NaN   45FFFB88       19555  \n",
      "10075        NaN   45FFFB88       19237  \n",
      "10076        NaN   45FFFB88       19555  \n",
      "10077        NaN   45FFFB88       18847  \n",
      "10078   0982A8C9   45FFFB88       18509  \n",
      "10079   0880543B   45FFFB88       19532  \n",
      "10080   0880543B   45FFFB88       19468  \n",
      "10081   0880543B   45FFFB88       19555  \n",
      "10082   0880543B   45FFFB88       19131  \n",
      "10083   0880543B   45FFFB88       19496  \n",
      "10084   0880543B   45FFFB88       19519  \n",
      "\n",
      "[18603 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "print((frame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf__max_df: (0.25, 0.50, 0.75)\n",
    "tfidf__ngram_range: ((1, 1), (1, 2), (1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Structural trend analysis for online social networks']\n",
      " ['SQL/AA: Executing SQL on an Asymmetric Architecture']\n",
      " ['SCOUT: prefetching for latent structure following queries']\n",
      " ...\n",
      " ['On the Comprehension of Program Comprehension']\n",
      " ['Some Code Smells Have a Significant but Small Effect on Faults']\n",
      " ['Amplifying Tests to Validate Exception Handling Code: An Extended Study in the Mobile Application Domain']]\n",
      "[['vldb']\n",
      " ['vldb']\n",
      " ['vldb']\n",
      " ...\n",
      " ['icse']\n",
      " ['icse']\n",
      " ['icse']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jayanth/anaconda3/envs/uwindsor/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/jayanth/anaconda3/envs/uwindsor/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "data_x = frame[['title']].as_matrix()\n",
    "print(data_x)\n",
    "data_y = frame[['conference_short']].as_matrix()\n",
    "print(data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data\n",
    "stratified_split = StratifiedShuffleSplit(n_splits=2, test_size=0.33)\n",
    "for train_index, test_index in stratified_split.split(data_x, data_y):\n",
    "    x_train, x_test = data_x[train_index], data_x[test_index]\n",
    "    y_train, y_test = data_y[train_index], data_y[test_index]\n",
    "train_x = [x[0].strip() for x in x_train.tolist()]\n",
    "test_x = [x[0].strip() for x in x_test.tolist()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_NB = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "    ('clf', OneVsRestClassifier(MultinomialNB(\n",
    "        fit_prior=True, class_prior=None))),\n",
    "])\n",
    "parameters_NB = {\n",
    "    'tfidf__max_df': (0.25, 0.5, 0.75),\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'clf__estimator__alpha': (1e-2, 1e-3)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_SVM = Pipeline(\n",
    "    [\n",
    "    ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "    ('clf', OneVsRestClassifier(LinearSVC()))])\n",
    "parameters_SVM = {\n",
    "    'tfidf__max_df': (0.25, 0.5, 0.75),\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    \"clf__estimator__C\": [0.01, 0.1, 1],\n",
    "    \"clf__estimator__class_weight\": ['balanced', None],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_logistic = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "    ('clf', OneVsRestClassifier(LogisticRegression(solver='sag')))])\n",
    "parameters_logistic = {\n",
    "    'tfidf__max_df': (0.25, 0.5, 0.75),\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    \"clf__estimator__C\": [0.01, 0.1, 1],\n",
    "    \"clf__estimator__class_weight\": ['balanced', None],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 54 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:    7.8s\n",
      "[Parallel(n_jobs=2)]: Done 108 out of 108 | elapsed:   32.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set fot SVM are:\n",
      "[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.25, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 3), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words={'until', 'are', \"aren't\", 'when', 'which', \"weren't\", 'me', 'having', 'those', 'an', 'mightn', 'there', 'my', 'above', 'd', \"didn't\", 'not', 'wouldn', 'am', 'as', 'was', 'shan', 'now', 'o', 'very', 'these', 'the', 'through', 'ain', 'haven', 'under', 'he', 'can', 'yourselves', \"shan't\", '...er', 'between', 'but', 'him', 'in', \"couldn't\", 'aren', 'why', 'does', 'she', 'i', 'both', 'couldn'},\n",
      "        strip_accents=None, sublinear_tf=False,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)), ('clf', OneVsRestClassifier(estimator=LinearSVC(C=1, class_weight='balanced', dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0),\n",
      "          n_jobs=None))]\n",
      "Applying best classifier on test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        icse       0.92      0.95      0.94      3328\n",
      "      sigmod       0.55      0.48      0.51      1384\n",
      "        vldb       0.56      0.58      0.57      1427\n",
      "\n",
      "   micro avg       0.76      0.76      0.76      6139\n",
      "   macro avg       0.68      0.67      0.67      6139\n",
      "weighted avg       0.75      0.76      0.76      6139\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid_search_tune = GridSearchCV(\n",
    "    pipeline_SVM, parameters_SVM, cv=2, n_jobs=2, verbose=3)\n",
    "grid_search_tune.fit(train_x, y_train)\n",
    "\n",
    "\n",
    "print(\"Best parameters set fot SVM are:\")\n",
    "print(grid_search_tune.best_estimator_.steps)\n",
    "\n",
    "# measuring performance on test set\n",
    "print(\"Applying best classifier on test data:\")\n",
    "best_clf = grid_search_tune.best_estimator_\n",
    "predictions = best_clf.predict(test_x)\n",
    "\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 18 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=2)]: Done  36 out of  36 | elapsed:   11.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.25, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 3), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words={'until', 'are', \"aren't\", 'when', 'which', \"weren't\", 'me', 'having', 'those', 'an', 'mightn', 'there', 'my', 'above', 'd', \"didn't\", 'not', 'wouldn', 'am', 'as', 'was', 'shan', 'now', 'o', 'very', 'these', 'the', 'through', 'ain', 'haven', 'under', 'he', 'can', 'yourselves', \"shan't\", '...er', 'between', 'but', 'him', 'in', \"couldn't\", 'aren', 'why', 'does', 'she', 'i', 'both', 'couldn'},\n",
      "        strip_accents=None, sublinear_tf=False,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)), ('clf', OneVsRestClassifier(estimator=MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True),\n",
      "          n_jobs=None))]\n",
      "Applying best classifier on test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        icse       0.89      0.95      0.92      3328\n",
      "      sigmod       0.54      0.46      0.50      1384\n",
      "        vldb       0.55      0.55      0.55      1427\n",
      "\n",
      "   micro avg       0.75      0.75      0.75      6139\n",
      "   macro avg       0.66      0.66      0.66      6139\n",
      "weighted avg       0.74      0.75      0.74      6139\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid_search_tune = GridSearchCV(\n",
    "    pipeline_NB\n",
    "    , parameters_NB, cv=2, n_jobs=2, verbose=3)\n",
    "grid_search_tune.fit(train_x, y_train)\n",
    "\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print(grid_search_tune.best_estimator_.steps)\n",
    "\n",
    "# measuring performance on test set\n",
    "print(\"Applying best classifier on test data:\")\n",
    "best_clf = grid_search_tune.best_estimator_\n",
    "predictions = best_clf.predict(test_x)\n",
    "\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 54 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:   13.6s\n",
      "[Parallel(n_jobs=2)]: Done 108 out of 108 | elapsed:   55.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.5, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 3), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words={'until', 'are', \"aren't\", 'when', 'which', \"weren't\", 'me', 'having', 'those', 'an', 'mightn', 'there', 'my', 'above', 'd', \"didn't\", 'not', 'wouldn', 'am', 'as', 'was', 'shan', 'now', 'o', 'very', 'these', 'the', 'through', 'ain', 'haven', 'under', 'he', 'can', 'yourselves', \"shan't\", '...er', 'between', 'but', 'him', 'in', \"couldn't\", 'aren', 'why', 'does', 'she', 'i', 'both', 'couldn'},\n",
      "        strip_accents=None, sublinear_tf=False,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)), ('clf', OneVsRestClassifier(estimator=LogisticRegression(C=1, class_weight='balanced', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='warn', n_jobs=None, penalty='l2', random_state=None,\n",
      "          solver='sag', tol=0.0001, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "Applying best classifier on test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        icse       0.91      0.94      0.93      3328\n",
      "      sigmod       0.53      0.45      0.49      1384\n",
      "        vldb       0.55      0.59      0.57      1427\n",
      "\n",
      "   micro avg       0.75      0.75      0.75      6139\n",
      "   macro avg       0.67      0.66      0.66      6139\n",
      "weighted avg       0.74      0.75      0.75      6139\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid_search_tune = GridSearchCV(\n",
    "    pipeline_logistic\n",
    "    , parameters_logistic, cv=2, n_jobs=2, verbose=3)\n",
    "grid_search_tune.fit(train_x, y_train)\n",
    "\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print(grid_search_tune.best_estimator_.steps)\n",
    "\n",
    "# measuring performance on test set\n",
    "print(\"Applying best classifier on test data:\")\n",
    "best_clf = grid_search_tune.best_estimator_\n",
    "predictions = best_clf.predict(test_x)\n",
    "\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['icse']\n",
      " ['sigmod']\n",
      " ['icse']\n",
      " ...\n",
      " ['icse']\n",
      " ['sigmod']\n",
      " ['icse']]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12464\n"
     ]
    }
   ],
   "source": [
    "print(len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6139\n"
     ]
    }
   ],
   "source": [
    "print(len(predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (uwindsor)",
   "language": "python",
   "name": "uwindsor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
